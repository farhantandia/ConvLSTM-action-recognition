{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential, Model \n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from keras_video import VideoFrameGenerator\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ApplyEyeMakeup',\n",
       " 'ApplyLipstick',\n",
       " 'Archery',\n",
       " 'BabyCrawling',\n",
       " 'BalanceBeam',\n",
       " 'BandMarching',\n",
       " 'BaseballPitch',\n",
       " 'Basketball',\n",
       " 'BasketballDunk',\n",
       " 'BenchPress',\n",
       " 'Biking',\n",
       " 'Billiards',\n",
       " 'BlowDryHair',\n",
       " 'BlowingCandles',\n",
       " 'BodyWeightSquats',\n",
       " 'Bowling',\n",
       " 'BoxingPunchingBag',\n",
       " 'BoxingSpeedBag',\n",
       " 'BreastStroke',\n",
       " 'BrushingTeeth',\n",
       " 'CleanAndJerk',\n",
       " 'CliffDiving',\n",
       " 'CricketBowling',\n",
       " 'CricketShot',\n",
       " 'CuttingInKitchen',\n",
       " 'Diving',\n",
       " 'Drumming',\n",
       " 'Fencing',\n",
       " 'FieldHockeyPenalty',\n",
       " 'FloorGymnastics',\n",
       " 'FrisbeeCatch',\n",
       " 'FrontCrawl',\n",
       " 'GolfSwing',\n",
       " 'Haircut',\n",
       " 'HammerThrow',\n",
       " 'Hammering',\n",
       " 'HandstandPushups',\n",
       " 'HandstandWalking',\n",
       " 'HeadMassage',\n",
       " 'HighJump',\n",
       " 'HorseRace',\n",
       " 'HorseRiding',\n",
       " 'HulaHoop',\n",
       " 'IceDancing',\n",
       " 'JavelinThrow',\n",
       " 'JugglingBalls',\n",
       " 'JumpRope',\n",
       " 'JumpingJack',\n",
       " 'Kayaking',\n",
       " 'Knitting',\n",
       " 'LongJump',\n",
       " 'Lunges',\n",
       " 'MilitaryParade',\n",
       " 'Mixing',\n",
       " 'MoppingFloor',\n",
       " 'Nunchucks',\n",
       " 'ParallelBars',\n",
       " 'PizzaTossing',\n",
       " 'PlayingCello',\n",
       " 'PlayingDaf',\n",
       " 'PlayingDhol',\n",
       " 'PlayingFlute',\n",
       " 'PlayingGuitar',\n",
       " 'PlayingPiano',\n",
       " 'PlayingSitar',\n",
       " 'PlayingTabla',\n",
       " 'PlayingViolin',\n",
       " 'PoleVault',\n",
       " 'PommelHorse',\n",
       " 'PullUps',\n",
       " 'Punch',\n",
       " 'PushUps',\n",
       " 'Rafting',\n",
       " 'RockClimbingIndoor',\n",
       " 'RopeClimbing',\n",
       " 'Rowing',\n",
       " 'SalsaSpin',\n",
       " 'ShavingBeard',\n",
       " 'Shotput',\n",
       " 'SkateBoarding',\n",
       " 'Skiing',\n",
       " 'Skijet',\n",
       " 'SkyDiving',\n",
       " 'SoccerJuggling',\n",
       " 'SoccerPenalty',\n",
       " 'StillRings',\n",
       " 'SumoWrestling',\n",
       " 'Surfing',\n",
       " 'Swing',\n",
       " 'TableTennisShot',\n",
       " 'TaiChi',\n",
       " 'TennisSwing',\n",
       " 'ThrowDiscus',\n",
       " 'TrampolineJumping',\n",
       " 'Typing',\n",
       " 'UnevenBars',\n",
       " 'VolleyballSpiking',\n",
       " 'WalkingWithDog',\n",
       " 'WallPushups',\n",
       " 'WritingOnBoard',\n",
       " 'YoYo']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# classes = [\"Backstroke\", \"Breaststroke\", \"Freestyle\"]\n",
    "with open('ucf101_data/classInd.txt') as f:\n",
    "    classes = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "classes = [x.strip() for x in classes] \n",
    "classes.sort()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_height , img_width = 64, 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: 101 classes for 9537 files for train\n"
     ]
    }
   ],
   "source": [
    "# some global params\n",
    "SIZE = (img_height, img_width)\n",
    "CHANNELS = 3\n",
    "NBFRAME =20\n",
    "BS = 9537\n",
    "# pattern to get videos and classes\n",
    "glob_pattern='ucf101_data/train/{classname}/*.avi'\n",
    "# for data augmentation\n",
    "data_aug = ImageDataGenerator(\n",
    "#     zoom_range=1.5,\n",
    "#     horizontal_flip=True,\n",
    "#     rotation_range=8,\n",
    "#     width_shift_range=.2,\n",
    "#     height_shift_range=.2\n",
    ")\n",
    "# Create video frame generator\n",
    "\n",
    "train = VideoFrameGenerator(\n",
    "    classes=classes, \n",
    "    glob_pattern=glob_pattern,\n",
    "    nb_frames=NBFRAME,\n",
    "#     split_val=0.25, \n",
    "#     shuffle=True,\n",
    "    batch_size=BS,\n",
    "    target_shape=SIZE,\n",
    "    nb_channel=CHANNELS,\n",
    "#     transformation=data_aug,\n",
    "    use_frame_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: 101 classes for 3783 files for train\n"
     ]
    }
   ],
   "source": [
    "\n",
    "glob_test='ucf101_data/test/{classname}/*.avi'\n",
    "valid = VideoFrameGenerator(\n",
    "    classes=classes, \n",
    "    glob_pattern=glob_test,\n",
    "    nb_frames=NBFRAME,\n",
    "#     split=.2, \n",
    "    shuffle=True,\n",
    "    batch_size=3783,\n",
    "    target_shape=SIZE,\n",
    "    nb_channel=CHANNELS,\n",
    "#     transformation=data_aug,\n",
    "    use_frame_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: 101 classes for 0 files for validation\n"
     ]
    }
   ],
   "source": [
    "valid = train.get_validation_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_video.generator.VideoFrameGenerator at 0x24fc8e834a8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 9.38 MiB for an array with shape (20, 640, 64, 3) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-581bc1b2cd02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# x_test, y_test = next(valid)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\yolov4-gpu\\lib\\site-packages\\keras_video\\generator.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\yolov4-gpu\\lib\\site-packages\\keras_video\\generator.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;34m\"\"\" Return next element\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m         \u001b[0melem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_current\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_current\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_current\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\yolov4-gpu\\lib\\site-packages\\keras_video\\generator.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    342\u001b[0m                     \u001b[0mnbframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m                     \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m                     force_no_headers=not self.use_video_header)\n\u001b[0m\u001b[0;32m    345\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mframes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m                     \u001b[1;31m# avoid failure, nevermind that video...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\yolov4-gpu\\lib\\site-packages\\keras_video\\generator.py\u001b[0m in \u001b[0;36m_get_frames\u001b[1;34m(self, video, nbframe, shape, force_no_headers)\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 9.38 MiB for an array with shape (20, 640, 64, 3) and data type float32"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "x_train, y_train = next(train)\n",
    "# x_test, y_test = next(valid)\n",
    "\n",
    "elapsed_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(str(elapsed_time/60)+' minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9537, 20, 64, 100, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = \"ucf101_data/train\"\n",
    "# img_height , img_width = 200, 180\n",
    "# seq_len = 60\n",
    " \n",
    "# #  Creating frames from videos\n",
    "# def frames_extraction(video_path):\n",
    "#     frames_list = []\n",
    "     \n",
    "#     vidObj = cv2.VideoCapture(video_path)\n",
    "#     # Used as counter variable \n",
    "#     count = 1\n",
    " \n",
    "#     while count <= seq_len: \n",
    "         \n",
    "#         success, image = vidObj.read() \n",
    "#         if success:\n",
    "#             image = cv2.resize(image, (img_height, img_width))\n",
    "#             frames_list.append(image)\n",
    "#             count += 1\n",
    "#         else:\n",
    "#             print(\"Defected frame\")\n",
    "#             break\n",
    " \n",
    "            \n",
    "#     return frames_list\n",
    " \n",
    "# def create_data(input_dir):\n",
    "#     X = []\n",
    "#     Y = []\n",
    "     \n",
    "#     classes_list = os.listdir(input_dir)\n",
    "     \n",
    "#     for c in classes_list:\n",
    "#         print(c)\n",
    "#         files_list = os.listdir(os.path.join(input_dir, c))\n",
    "#         for f in files_list:\n",
    "#             frames = frames_extraction(os.path.join(os.path.join(input_dir, c), f))\n",
    "#             if len(frames) == seq_len:\n",
    "#                 X.append(frames)\n",
    "             \n",
    "#                 y = [0]*len(classes)\n",
    "#                 y[classes.index(c)] = 1\n",
    "#                 Y.append(y)\n",
    "     \n",
    "#     X = np.asarray(X)\n",
    "#     Y = np.asarray(Y)\n",
    "#     return X, Y\n",
    " \n",
    "# X, Y = create_data(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [9537, 7152]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-fc8145e6c4ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'best_model_convlstm_fix.h5'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m model.add(ConvLSTM2D(filters = 64, kernel_size = (5, 5), padding='same',return_sequences = True, data_format = \"channels_last\", \n",
      "\u001b[1;32m~\\anaconda3\\envs\\yolov4-gpu\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2125\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid parameters passed: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2127\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2129\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\yolov4-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    290\u001b[0m     \"\"\"\n\u001b[0;32m    291\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\yolov4-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 256\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [9537, 7152]"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.25, shuffle=True, random_state=0)\n",
    "filepath = 'best_model_convlstm_fix.h5'\n",
    "\n",
    "model = Sequential()\n",
    "model.add(ConvLSTM2D(filters = 64, kernel_size = (5, 5), padding='same',return_sequences = True, data_format = \"channels_last\", \n",
    "                     input_shape = (NBFRAME, img_width, img_height, 3),kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\n",
    "# model.add(ConvLSTM2D(filters = 64, kernel_size = (3, 3), padding='same',return_sequences = True, data_format = \"channels_last\", \n",
    "#                      input_shape = (NBFRAME,64,64, 3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(ConvLSTM2D(filters = 32, kernel_size = (5, 5), return_sequences = False, data_format = \"channels_last\",kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(classes), activation = \"softmax\"))\n",
    " \n",
    "model.summary()\n",
    "'''\n",
    "model = Sequential()\n",
    "# input_shape: (time_steps, map_height, map_width, channels)\n",
    "model.add(ConvLSTM2D(filters = 32, kernel_size = (3, 3),  input_shape = (NBFRAME, img_width, img_height, 3), return_sequences = True))\n",
    "model.add(ConvLSTM2D(filters = 32, kernel_size = (3, 3), return_sequences = True))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(ConvLSTM2D(filters = 32, kernel_size = (3, 3), return_sequences = True))\n",
    "model.add(ConvLSTM2D(filters = 32, kernel_size = (3, 3), return_sequences = True))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(MaxPooling3D((1, 2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(ConvLSTM2D(filters = 32, kernel_size = (3, 3), return_sequences = True))\n",
    "model.add(ConvLSTM2D(filters = 32, kernel_size = (3, 3), return_sequences = True))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(LeakyReLU(alpha=0.2))\n",
    "#model.add(AveragePooling3D((1, 2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(ConvLSTM2D(filters = 32, kernel_size = (3, 3), return_sequences = True))\n",
    "model.add(ConvLSTM2D(filters = 32, kernel_size = (3, 3), return_sequences = False))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(AveragePooling2D((2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()\n",
    "'''\n",
    "opt = optimizers.Adam(lr=0.00005)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n",
    " \n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "stop = EarlyStopping(monitor='val_loss', patience =5,\n",
    "                      verbose=0, mode='auto', baseline=None, \n",
    "                      restore_best_weights=False)\n",
    "callbacks = [checkpoint,stop]\n",
    " \n",
    "history = model.fit(x = X_train, y = y_train, epochs=400, batch_size = 2 , shuffle=True, validation_data=(X_test,y_test), callbacks=callbacks)\n",
    "# history = model.fit_generator(\n",
    "#     train,\n",
    "#     validation_data=valid,\n",
    "#     verbose=1,\n",
    "#     epochs=400, \n",
    "#     callbacks=callbacks\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(X_test)\n",
    "# y_pred = np.argmax(y_pred, axis = 1)\n",
    "# # y_test = np.argmax(y_test, axis = 1)\n",
    " \n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use LSTM model to predict\n",
    "\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# y_pred_ohe = model.predict(X_test)\n",
    "# y_pred_labels = np.argmax(y_pred_ohe, axis=1)\n",
    "# y_true_labels = y_test\n",
    "# confusion_matrix = metrics.confusion_matrix(y_true=y_true_labels, y_pred=y_pred_labels)\n",
    "# print(y_true_labels)\n",
    "\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "# sns.heatmap(confusion_matrix, xticklabels=classes, yticklabels=classes, annot=True, fmt=\"d\");\n",
    "# plt.title(\"Confusion matrix\")\n",
    "# plt.ylabel('True label')\n",
    "# plt.xlabel('Predicted label')\n",
    "# plt.show();\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_har.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
