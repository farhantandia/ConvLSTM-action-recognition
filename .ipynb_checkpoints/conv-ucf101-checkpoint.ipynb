{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python\n",
    "pip install scikit-learn\n",
    "pip install keras-video-generators\n",
    "apt-get update\n",
    "apt-get install sudo\n",
    "sudo apt update\n",
    "sudo apt install -y libgl1-mesa-glx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential, Model \n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from keras_video import VideoFrameGenerator\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ApplyEyeMakeup',\n",
       " 'ApplyLipstick',\n",
       " 'Archery',\n",
       " 'BabyCrawling',\n",
       " 'BalanceBeam',\n",
       " 'BandMarching',\n",
       " 'BaseballPitch',\n",
       " 'Basketball',\n",
       " 'BasketballDunk',\n",
       " 'BenchPress',\n",
       " 'Biking',\n",
       " 'Billiards',\n",
       " 'BlowDryHair',\n",
       " 'BlowingCandles',\n",
       " 'BodyWeightSquats',\n",
       " 'Bowling',\n",
       " 'BoxingPunchingBag',\n",
       " 'BoxingSpeedBag',\n",
       " 'BreastStroke',\n",
       " 'BrushingTeeth',\n",
       " 'CleanAndJerk',\n",
       " 'CliffDiving',\n",
       " 'CricketBowling',\n",
       " 'CricketShot',\n",
       " 'CuttingInKitchen',\n",
       " 'Diving',\n",
       " 'Drumming',\n",
       " 'Fencing',\n",
       " 'FieldHockeyPenalty',\n",
       " 'FloorGymnastics',\n",
       " 'FrisbeeCatch',\n",
       " 'FrontCrawl',\n",
       " 'GolfSwing',\n",
       " 'Haircut',\n",
       " 'HammerThrow',\n",
       " 'Hammering',\n",
       " 'HandstandPushups',\n",
       " 'HandstandWalking',\n",
       " 'HeadMassage',\n",
       " 'HighJump',\n",
       " 'HorseRace',\n",
       " 'HorseRiding',\n",
       " 'HulaHoop',\n",
       " 'IceDancing',\n",
       " 'JavelinThrow',\n",
       " 'JugglingBalls',\n",
       " 'JumpRope',\n",
       " 'JumpingJack',\n",
       " 'Kayaking',\n",
       " 'Knitting',\n",
       " 'LongJump',\n",
       " 'Lunges',\n",
       " 'MilitaryParade',\n",
       " 'Mixing',\n",
       " 'MoppingFloor',\n",
       " 'Nunchucks',\n",
       " 'ParallelBars',\n",
       " 'PizzaTossing',\n",
       " 'PlayingCello',\n",
       " 'PlayingDaf',\n",
       " 'PlayingDhol',\n",
       " 'PlayingFlute',\n",
       " 'PlayingGuitar',\n",
       " 'PlayingPiano',\n",
       " 'PlayingSitar',\n",
       " 'PlayingTabla',\n",
       " 'PlayingViolin',\n",
       " 'PoleVault',\n",
       " 'PommelHorse',\n",
       " 'PullUps',\n",
       " 'Punch',\n",
       " 'PushUps',\n",
       " 'Rafting',\n",
       " 'RockClimbingIndoor',\n",
       " 'RopeClimbing',\n",
       " 'Rowing',\n",
       " 'SalsaSpin',\n",
       " 'ShavingBeard',\n",
       " 'Shotput',\n",
       " 'SkateBoarding',\n",
       " 'Skiing',\n",
       " 'Skijet',\n",
       " 'SkyDiving',\n",
       " 'SoccerJuggling',\n",
       " 'SoccerPenalty',\n",
       " 'StillRings',\n",
       " 'SumoWrestling',\n",
       " 'Surfing',\n",
       " 'Swing',\n",
       " 'TableTennisShot',\n",
       " 'TaiChi',\n",
       " 'TennisSwing',\n",
       " 'ThrowDiscus',\n",
       " 'TrampolineJumping',\n",
       " 'Typing',\n",
       " 'UnevenBars',\n",
       " 'VolleyballSpiking',\n",
       " 'WalkingWithDog',\n",
       " 'WallPushups',\n",
       " 'WritingOnBoard',\n",
       " 'YoYo']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# classes = [\"Backstroke\", \"Breaststroke\", \"Freestyle\"]\n",
    "with open('ucf101_data/classInd.txt') as f:\n",
    "    classes = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "classes = [x.strip() for x in classes] \n",
    "classes.sort()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height , img_width = 64, 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class ApplyEyeMakeup, validation count: 36, train count: 109\n",
      "class ApplyLipstick, validation count: 28, train count: 86\n",
      "class Archery, validation count: 36, train count: 109\n",
      "class BabyCrawling, validation count: 33, train count: 99\n",
      "class BalanceBeam, validation count: 27, train count: 81\n",
      "class BandMarching, validation count: 38, train count: 117\n",
      "class BaseballPitch, validation count: 37, train count: 113\n",
      "class Basketball, validation count: 33, train count: 101\n",
      "class BasketballDunk, validation count: 32, train count: 99\n",
      "class BenchPress, validation count: 40, train count: 120\n",
      "class Biking, validation count: 33, train count: 101\n",
      "class Billiards, validation count: 37, train count: 113\n",
      "class BlowDryHair, validation count: 32, train count: 99\n",
      "class BlowingCandles, validation count: 27, train count: 82\n",
      "class BodyWeightSquats, validation count: 28, train count: 84\n",
      "class Bowling, validation count: 38, train count: 117\n",
      "class BoxingPunchingBag, validation count: 40, train count: 123\n",
      "class BoxingSpeedBag, validation count: 33, train count: 101\n",
      "class BreastStroke, validation count: 25, train count: 76\n",
      "class BrushingTeeth, validation count: 32, train count: 99\n",
      "class CleanAndJerk, validation count: 28, train count: 84\n",
      "class CliffDiving, validation count: 34, train count: 104\n",
      "class CricketBowling, validation count: 34, train count: 105\n",
      "class CricketShot, validation count: 41, train count: 126\n",
      "class CuttingInKitchen, validation count: 27, train count: 83\n",
      "class Diving, validation count: 37, train count: 113\n",
      "class Drumming, validation count: 40, train count: 121\n",
      "class Fencing, validation count: 27, train count: 84\n",
      "class FieldHockeyPenalty, validation count: 31, train count: 95\n",
      "class FloorGymnastics, validation count: 31, train count: 94\n",
      "class FrisbeeCatch, validation count: 31, train count: 95\n",
      "class FrontCrawl, validation count: 34, train count: 103\n",
      "class GolfSwing, validation count: 34, train count: 105\n",
      "class Haircut, validation count: 32, train count: 98\n",
      "class HammerThrow, validation count: 37, train count: 113\n",
      "class Hammering, validation count: 35, train count: 105\n",
      "class HandstandPushups, validation count: 32, train count: 96\n",
      "class HandstandWalking, validation count: 27, train count: 84\n",
      "class HeadMassage, validation count: 36, train count: 111\n",
      "class HighJump, validation count: 30, train count: 93\n",
      "class HorseRace, validation count: 31, train count: 93\n",
      "class HorseRiding, validation count: 41, train count: 123\n",
      "class HulaHoop, validation count: 31, train count: 94\n",
      "class IceDancing, validation count: 39, train count: 119\n",
      "class JavelinThrow, validation count: 29, train count: 88\n",
      "class JugglingBalls, validation count: 30, train count: 91\n",
      "class JumpRope, validation count: 36, train count: 108\n",
      "class JumpingJack, validation count: 30, train count: 93\n",
      "class Kayaking, validation count: 35, train count: 106\n",
      "class Knitting, validation count: 30, train count: 93\n",
      "class LongJump, validation count: 32, train count: 99\n",
      "class Lunges, validation count: 31, train count: 96\n",
      "class MilitaryParade, validation count: 31, train count: 94\n",
      "class Mixing, validation count: 34, train count: 102\n",
      "class MoppingFloor, validation count: 27, train count: 83\n",
      "class Nunchucks, validation count: 33, train count: 99\n",
      "class ParallelBars, validation count: 28, train count: 86\n",
      "class PizzaTossing, validation count: 28, train count: 85\n",
      "class PlayingCello, validation count: 41, train count: 123\n",
      "class PlayingDaf, validation count: 37, train count: 114\n",
      "class PlayingDhol, validation count: 41, train count: 123\n",
      "class PlayingFlute, validation count: 38, train count: 117\n",
      "class PlayingGuitar, validation count: 40, train count: 120\n",
      "class PlayingPiano, validation count: 26, train count: 79\n",
      "class PlayingSitar, validation count: 39, train count: 118\n",
      "class PlayingTabla, validation count: 27, train count: 84\n",
      "class PlayingViolin, validation count: 25, train count: 75\n",
      "class PoleVault, validation count: 37, train count: 112\n",
      "class PommelHorse, validation count: 30, train count: 93\n",
      "class PullUps, validation count: 25, train count: 75\n",
      "class Punch, validation count: 40, train count: 120\n",
      "class PushUps, validation count: 25, train count: 77\n",
      "class Rafting, validation count: 27, train count: 84\n",
      "class RockClimbingIndoor, validation count: 36, train count: 108\n",
      "class RopeClimbing, validation count: 29, train count: 90\n",
      "class Rowing, validation count: 34, train count: 103\n",
      "class SalsaSpin, validation count: 33, train count: 100\n",
      "class ShavingBeard, validation count: 40, train count: 121\n",
      "class Shotput, validation count: 36, train count: 108\n",
      "class SkateBoarding, validation count: 30, train count: 90\n",
      "class Skiing, validation count: 33, train count: 102\n",
      "class Skijet, validation count: 25, train count: 75\n",
      "class SkyDiving, validation count: 27, train count: 83\n",
      "class SoccerJuggling, validation count: 36, train count: 111\n",
      "class SoccerPenalty, validation count: 34, train count: 103\n",
      "class StillRings, validation count: 28, train count: 84\n",
      "class SumoWrestling, validation count: 29, train count: 87\n",
      "class Surfing, validation count: 31, train count: 95\n",
      "class Swing, validation count: 32, train count: 99\n",
      "class TableTennisShot, validation count: 35, train count: 105\n",
      "class TaiChi, validation count: 25, train count: 75\n",
      "class TennisSwing, validation count: 41, train count: 125\n",
      "class ThrowDiscus, validation count: 32, train count: 98\n",
      "class TrampolineJumping, validation count: 29, train count: 90\n",
      "class Typing, validation count: 34, train count: 102\n",
      "class UnevenBars, validation count: 26, train count: 78\n",
      "class VolleyballSpiking, validation count: 29, train count: 87\n",
      "class WalkingWithDog, validation count: 30, train count: 93\n",
      "class WallPushups, validation count: 32, train count: 98\n",
      "class WritingOnBoard, validation count: 38, train count: 114\n",
      "class YoYo, validation count: 32, train count: 96\n",
      "Total data: 101 classes for 10027 files for train\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# some global params\n",
    "SIZE = (img_height, img_width)\n",
    "CHANNELS = 3\n",
    "NBFRAME =50\n",
    "BS = 4\n",
    "# pattern to get videos and classes\n",
    "glob_pattern='ucf101_data/train/{classname}/*.avi'\n",
    "# for data augmentation\n",
    "data_aug = ImageDataGenerator(\n",
    "#     zoom_range=1.5,\n",
    "#     horizontal_flip=True,\n",
    "#     rotation_range=8,\n",
    "#     width_shift_range=.2,\n",
    "#     height_shift_range=.2\n",
    ")\n",
    "# Create video frame generator\n",
    "\n",
    "train = VideoFrameGenerator(\n",
    "    classes=classes, \n",
    "    glob_pattern=glob_pattern,\n",
    "    nb_frames=NBFRAME,\n",
    "    split_val=0.25, \n",
    "#     shuffle=True,\n",
    "    batch_size=BS,\n",
    "    target_shape=SIZE,\n",
    "    nb_channel=CHANNELS,\n",
    "#     transformation=data_aug,\n",
    "    use_frame_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid = VideoFrameGenerator(\n",
    "#     classes=classes, \n",
    "#     glob_pattern=glob_test,\n",
    "#     nb_frames=NBFRAME,\n",
    "# #     split=.2, \n",
    "#     shuffle=True,\n",
    "#     batch_size=3783,\n",
    "#     target_shape=SIZE,\n",
    "#     nb_channel=CHANNELS,\n",
    "# #     transformation=data_aug,\n",
    "#     use_frame_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: 101 classes for 3293 files for validation\n"
     ]
    }
   ],
   "source": [
    "valid = train.get_validation_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frame count is not OK for video ucf101_data/train/BodyWeightSquats\\v_BodyWeightSquats_g08_c03.avi, 50 total, 49 extracted\n",
      "Frame count is not OK for video ucf101_data/train/Lunges\\v_Lunges_g20_c01.avi, 48 total, 48 extracted\n",
      "Frame count is not OK for video ucf101_data/train/BodyWeightSquats\\v_BodyWeightSquats_g03_c03.avi, 48 total, 48 extracted\n",
      "Frame count is not OK for video ucf101_data/train/BlowingCandles\\v_BlowingCandles_g25_c03.avi, 40 total, 40 extracted\n",
      "Frame count is not OK for video ucf101_data/train/Lunges\\v_Lunges_g20_c02.avi, 48 total, 47 extracted\n",
      "Frame count is not OK for video ucf101_data/train/BaseballPitch\\v_BaseballPitch_g06_c04.avi, 48 total, 47 extracted\n",
      "Frame count is not OK for video ucf101_data/train/BasketballDunk\\v_BasketballDunk_g07_c04.avi, 46 total, 46 extracted\n",
      "Frame count is not OK for video ucf101_data/train/BenchPress\\v_BenchPress_g15_c06.avi, 46 total, 45 extracted\n",
      "Frame count is not OK for video ucf101_data/train/Punch\\v_Punch_g01_c03.avi, 48 total, 48 extracted\n",
      "Frame count is not OK for video ucf101_data/train/CuttingInKitchen\\v_CuttingInKitchen_g19_c02.avi, 50 total, 49 extracted\n",
      "Frame count is not OK for video ucf101_data/train/PushUps\\v_PushUps_g16_c03.avi, 34 total, 33 extracted\n",
      "Frame count is not OK for video ucf101_data/train/BasketballDunk\\v_BasketballDunk_g13_c01.avi, 48 total, 47 extracted\n",
      "Frame count is not OK for video ucf101_data/train/SoccerPenalty\\v_SoccerPenalty_g12_c06.avi, 46 total, 45 extracted\n",
      "Frame count is not OK for video ucf101_data/train/BasketballDunk\\v_BasketballDunk_g07_c05.avi, 38 total, 37 extracted\n",
      "Frame count is not OK for video ucf101_data/train/SkyDiving\\v_SkyDiving_g02_c01.avi, 30 total, 30 extracted\n",
      "Frame count is not OK for video ucf101_data/train/FieldHockeyPenalty\\v_FieldHockeyPenalty_g03_c03.avi, 34 total, 34 extracted\n",
      "Frame count is not OK for video ucf101_data/train/BlowingCandles\\v_BlowingCandles_g05_c03.avi, 30 total, 30 extracted\n",
      "Frame count is not OK for video ucf101_data/train/BasketballDunk\\v_BasketballDunk_g04_c04.avi, 48 total, 48 extracted\n",
      "Frame count is not OK for video ucf101_data/train/Lunges\\v_Lunges_g20_c03.avi, 48 total, 47 extracted\n",
      "Frame count is not OK for video ucf101_data/train/PushUps\\v_PushUps_g16_c04.avi, 30 total, 29 extracted\n",
      "Frame count is not OK for video ucf101_data/train/Lunges\\v_Lunges_g20_c04.avi, 48 total, 48 extracted\n",
      "Frame count is not OK for video ucf101_data/train/BlowingCandles\\v_BlowingCandles_g24_c04.avi, 40 total, 40 extracted\n",
      "Frame count is not OK for video ucf101_data/train/CricketShot\\v_CricketShot_g16_c05.avi, 48 total, 47 extracted\n",
      "Frame count is not OK for video ucf101_data/train/PizzaTossing\\v_PizzaTossing_g03_c04.avi, 36 total, 36 extracted\n",
      "Frame count is not OK for video ucf101_data/train/BasketballDunk\\v_BasketballDunk_g07_c01.avi, 42 total, 42 extracted\n",
      "Frame count is not OK for video ucf101_data/train/FieldHockeyPenalty\\v_FieldHockeyPenalty_g17_c03.avi, 48 total, 48 extracted\n",
      "Frame count is not OK for video ucf101_data/train/BandMarching\\v_BandMarching_g05_c01.avi, 48 total, 47 extracted\n",
      "Frame count is not OK for video ucf101_data/train/SkyDiving\\v_SkyDiving_g15_c05.avi, 48 total, 48 extracted\n",
      "Frame count is not OK for video ucf101_data/train/HorseRiding\\v_HorseRiding_g14_c02.avi, 32 total, 32 extracted\n",
      "Frame count is not OK for video ucf101_data/train/BasketballDunk\\v_BasketballDunk_g07_c02.avi, 36 total, 35 extracted\n",
      "Frame count is not OK for video ucf101_data/train/Punch\\v_Punch_g02_c03.avi, 48 total, 48 extracted\n",
      "Frame count is not OK for video ucf101_data/train/JavelinThrow\\v_JavelinThrow_g10_c02.avi, 48 total, 48 extracted\n",
      "Frame count is not OK for video ucf101_data/train/CricketShot\\v_CricketShot_g21_c01.avi, 46 total, 46 extracted\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'start_time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-369d8cd8444f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melapsed_time\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m' minutes'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'start_time' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "x_train, y_train = next(train)\n",
    "x_test, y_test = next(valid)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(str(elapsed_time/60)+' minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.25, shuffle=True, random_state=0)\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d_12 (ConvLSTM2D) (None, 50, 64, 64, 64)    154624    \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 50, 64, 64, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_13 (ConvLSTM2D) (None, 60, 60, 32)        307328    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 60, 60, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 115200)            0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               14745728  \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 101)               13029     \n",
      "=================================================================\n",
      "Total params: 15,220,709\n",
      "Trainable params: 15,220,709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From <ipython-input-17-e0b2e2321a42>:36: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/400\n",
      " 231/2506 [=>............................] - ETA: 38:37 - loss: 4.6322 - accuracy: 0.0097"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-e0b2e2321a42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\yolov4-gpu\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m               \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m               instructions)\n\u001b[1;32m--> 324\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[0;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'deprecated'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\yolov4-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1827\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1828\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1829\u001b[1;33m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1831\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\yolov4-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\yolov4-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\yolov4-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\yolov4-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\yolov4-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\yolov4-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\yolov4-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\yolov4-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\yolov4-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "filepath = 'best_model_convlstm_fix.h5'\n",
    "\n",
    "model = Sequential()\n",
    "model.add(ConvLSTM2D(filters = 64, kernel_size = (3, 3), padding='same',return_sequences = True, data_format = \"channels_last\", \n",
    "                     input_shape = (NBFRAME, img_width, img_height, 3),kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\n",
    "# model.add(ConvLSTM2D(filters = 64, kernel_size = (3, 3), padding='same',return_sequences = True, data_format = \"channels_last\", \n",
    "#                      input_shape = (NBFRAME,64,64, 3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(ConvLSTM2D(filters = 32, kernel_size = (5, 5), return_sequences = False, data_format = \"channels_last\",kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(classes), activation = \"softmax\"))\n",
    " \n",
    "model.summary()\n",
    "\n",
    "opt = optimizers.Adam(lr=0.00005)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tfa.optimizers.NovoGrad(), metrics=[\"accuracy\"])\n",
    " \n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "stop = EarlyStopping(monitor='val_loss', patience =10,\n",
    "                      verbose=0, mode='auto', baseline=None, \n",
    "                      restore_best_weights=False)\n",
    "callbacks = [checkpoint,stop]\n",
    " \n",
    "# history = model.fit(x = x_train, y = y_train, epochs=400, batch_size = 2 , shuffle=True, validation_data=(x_test,y_test), callbacks=callbacks)\n",
    "history = model.fit_generator(\n",
    "    train,\n",
    "    validation_data=valid,\n",
    "    verbose=1,\n",
    "    epochs=400, \n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#print(X_train.shape)\n",
    "#plt.imshow(X_train[125][10])\n",
    "\n",
    "#plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2')\n"
     ]
    }
   ],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:1\", \"/gpu:2\"], cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\n",
    "#print('Number of devices: {}'.format(strategy.numde_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 20, 240, 160, 1)] 0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d (ConvLSTM2D)    (None, 20, 238, 158, 32)  38144     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 20, 238, 158, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, 20, 236, 156, 32)  73856     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20, 236, 156, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_2 (ConvLSTM2D)  (None, 20, 234, 154, 32)  73856     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 20, 234, 154, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_3 (ConvLSTM2D)  (None, 20, 232, 152, 32)  73856     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 20, 232, 152, 32)  0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_4 (ConvLSTM2D)  (None, 230, 150, 32)      73856     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 230, 150, 32)      0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1104000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                70656064  \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 70,989,827\n",
      "Trainable params: 70,989,827\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n",
      "INFO:tensorflow:batch_all_reduce: 19 all-reduces with algorithm = hierarchical_copy, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 19 all-reduces with algorithm = hierarchical_copy, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.1610 - accuracy: 0.3943INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "\n",
      "Epoch 00001: loss improved from inf to 1.16102, saving model to Farhan64_32.h5\n",
      "88/88 [==============================] - 67s 758ms/step - loss: 1.1610 - accuracy: 0.3943 - val_loss: 1.1003 - val_accuracy: 0.3548\n",
      "Epoch 2/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.1161 - accuracy: 0.4057\n",
      "Epoch 00002: loss improved from 1.16102 to 1.11611, saving model to Farhan64_32.h5\n",
      "88/88 [==============================] - 65s 737ms/step - loss: 1.1161 - accuracy: 0.4057 - val_loss: 1.0942 - val_accuracy: 0.3548\n",
      "Epoch 3/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.1520 - accuracy: 0.3314\n",
      "Epoch 00003: loss did not improve from 1.11611\n",
      "88/88 [==============================] - 64s 725ms/step - loss: 1.1520 - accuracy: 0.3314 - val_loss: 1.0867 - val_accuracy: 0.3763\n",
      "Epoch 4/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.0973 - accuracy: 0.3543\n",
      "Epoch 00004: loss improved from 1.11611 to 1.09733, saving model to Farhan64_32.h5\n",
      "88/88 [==============================] - 65s 740ms/step - loss: 1.0973 - accuracy: 0.3543 - val_loss: 1.0763 - val_accuracy: 0.4731\n",
      "Epoch 5/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.0731 - accuracy: 0.3886\n",
      "Epoch 00005: loss improved from 1.09733 to 1.07313, saving model to Farhan64_32.h5\n",
      "88/88 [==============================] - 65s 738ms/step - loss: 1.0731 - accuracy: 0.3886 - val_loss: 0.9613 - val_accuracy: 0.5054\n",
      "Epoch 6/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.9222 - accuracy: 0.5829\n",
      "Epoch 00006: loss improved from 1.07313 to 0.92222, saving model to Farhan64_32.h5\n",
      "88/88 [==============================] - 65s 739ms/step - loss: 0.9222 - accuracy: 0.5829 - val_loss: 0.9913 - val_accuracy: 0.4731\n",
      "Epoch 7/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.7832 - accuracy: 0.6743\n",
      "Epoch 00007: loss improved from 0.92222 to 0.78317, saving model to Farhan64_32.h5\n",
      "88/88 [==============================] - 65s 740ms/step - loss: 0.7832 - accuracy: 0.6743 - val_loss: 0.8944 - val_accuracy: 0.5269\n",
      "Epoch 8/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.6446 - accuracy: 0.7371\n",
      "Epoch 00008: loss improved from 0.78317 to 0.64463, saving model to Farhan64_32.h5\n",
      "88/88 [==============================] - 65s 740ms/step - loss: 0.6446 - accuracy: 0.7371 - val_loss: 0.6322 - val_accuracy: 0.6989\n",
      "Epoch 9/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.5177 - accuracy: 0.7943\n",
      "Epoch 00009: loss improved from 0.64463 to 0.51767, saving model to Farhan64_32.h5\n",
      "88/88 [==============================] - 65s 739ms/step - loss: 0.5177 - accuracy: 0.7943 - val_loss: 0.8436 - val_accuracy: 0.6774\n",
      "Epoch 10/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.3225 - accuracy: 0.9086\n",
      "Epoch 00010: loss improved from 0.51767 to 0.32251, saving model to Farhan64_32.h5\n",
      "88/88 [==============================] - 65s 741ms/step - loss: 0.3225 - accuracy: 0.9086 - val_loss: 0.8040 - val_accuracy: 0.7312\n",
      "Epoch 11/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.2731 - accuracy: 0.8629\n",
      "Epoch 00011: loss improved from 0.32251 to 0.27314, saving model to Farhan64_32.h5\n",
      "88/88 [==============================] - 65s 741ms/step - loss: 0.2731 - accuracy: 0.8629 - val_loss: 1.3186 - val_accuracy: 0.6667\n",
      "Epoch 12/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.3168 - accuracy: 0.8914\n",
      "Epoch 00012: loss did not improve from 0.27314\n",
      "88/88 [==============================] - 64s 728ms/step - loss: 0.3168 - accuracy: 0.8914 - val_loss: 1.1709 - val_accuracy: 0.6774\n",
      "Epoch 13/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.3573 - accuracy: 0.8686\n",
      "Epoch 00013: loss did not improve from 0.27314\n",
      "88/88 [==============================] - 64s 730ms/step - loss: 0.3573 - accuracy: 0.8686 - val_loss: 1.0590 - val_accuracy: 0.6882\n",
      "Epoch 14/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.1866 - accuracy: 0.9371\n",
      "Epoch 00014: loss improved from 0.27314 to 0.18656, saving model to Farhan64_32.h5\n",
      "88/88 [==============================] - 65s 740ms/step - loss: 0.1866 - accuracy: 0.9371 - val_loss: 1.2059 - val_accuracy: 0.6237\n",
      "Epoch 15/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.1644 - accuracy: 0.9314\n",
      "Epoch 00015: loss improved from 0.18656 to 0.16439, saving model to Farhan64_32.h5\n",
      "88/88 [==============================] - 65s 740ms/step - loss: 0.1644 - accuracy: 0.9314 - val_loss: 1.6793 - val_accuracy: 0.6022\n",
      "Epoch 16/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.2696 - accuracy: 0.9086\n",
      "Epoch 00016: loss did not improve from 0.16439\n",
      "88/88 [==============================] - 64s 731ms/step - loss: 0.2696 - accuracy: 0.9086 - val_loss: 0.9759 - val_accuracy: 0.6882\n",
      "Epoch 17/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.1407 - accuracy: 0.9714\n",
      "Epoch 00017: loss improved from 0.16439 to 0.14075, saving model to Farhan64_32.h5\n",
      "88/88 [==============================] - 65s 742ms/step - loss: 0.1407 - accuracy: 0.9714 - val_loss: 0.9663 - val_accuracy: 0.6989\n",
      "Epoch 18/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.9829\n",
      "Epoch 00018: loss improved from 0.14075 to 0.08730, saving model to Farhan64_32.h5\n",
      "88/88 [==============================] - 65s 743ms/step - loss: 0.0873 - accuracy: 0.9829 - val_loss: 1.1519 - val_accuracy: 0.6989\n",
      "Epoch 19/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.2226 - accuracy: 0.9029\n",
      "Epoch 00019: loss did not improve from 0.08730\n",
      "88/88 [==============================] - 64s 729ms/step - loss: 0.2226 - accuracy: 0.9029 - val_loss: 1.3765 - val_accuracy: 0.6559\n",
      "Epoch 20/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0695 - accuracy: 0.9943\n",
      "Epoch 00020: loss improved from 0.08730 to 0.06952, saving model to Farhan64_32.h5\n",
      "88/88 [==============================] - 65s 741ms/step - loss: 0.0695 - accuracy: 0.9943 - val_loss: 1.4382 - val_accuracy: 0.6882\n",
      "Epoch 21/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0686 - accuracy: 0.9829\n",
      "Epoch 00021: loss improved from 0.06952 to 0.06864, saving model to Farhan64_32.h5\n",
      "88/88 [==============================] - 65s 743ms/step - loss: 0.0686 - accuracy: 0.9829 - val_loss: 1.3317 - val_accuracy: 0.6989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0567 - accuracy: 0.9771\n",
      "Epoch 00022: loss improved from 0.06864 to 0.05671, saving model to Farhan64_32.h5\n",
      "88/88 [==============================] - 65s 743ms/step - loss: 0.0567 - accuracy: 0.9771 - val_loss: 1.4588 - val_accuracy: 0.6774\n",
      "Epoch 23/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.1245 - accuracy: 0.9657\n",
      "Epoch 00023: loss did not improve from 0.05671\n",
      "88/88 [==============================] - 64s 729ms/step - loss: 0.1245 - accuracy: 0.9657 - val_loss: 1.3194 - val_accuracy: 0.6989\n",
      "Epoch 24/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0811 - accuracy: 0.9714\n",
      "Epoch 00024: loss did not improve from 0.05671\n",
      "88/88 [==============================] - 64s 731ms/step - loss: 0.0811 - accuracy: 0.9714 - val_loss: 1.4956 - val_accuracy: 0.6882\n",
      "Epoch 25/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0770 - accuracy: 0.9829\n",
      "Epoch 00025: loss did not improve from 0.05671\n",
      "88/88 [==============================] - 64s 729ms/step - loss: 0.0770 - accuracy: 0.9829 - val_loss: 1.4053 - val_accuracy: 0.6882\n",
      "Epoch 26/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0707 - accuracy: 0.9829\n",
      "Epoch 00026: loss did not improve from 0.05671\n",
      "88/88 [==============================] - 64s 730ms/step - loss: 0.0707 - accuracy: 0.9829 - val_loss: 1.5727 - val_accuracy: 0.6989\n",
      "Epoch 27/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0788 - accuracy: 0.9829\n",
      "Epoch 00027: loss did not improve from 0.05671\n",
      "88/88 [==============================] - 64s 730ms/step - loss: 0.0788 - accuracy: 0.9829 - val_loss: 2.3252 - val_accuracy: 0.6667\n",
      "Epoch 28/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0789 - accuracy: 0.9657\n",
      "Epoch 00028: loss did not improve from 0.05671\n",
      "88/88 [==============================] - 64s 729ms/step - loss: 0.0789 - accuracy: 0.9657 - val_loss: 1.5730 - val_accuracy: 0.6774\n",
      "Epoch 29/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0538 - accuracy: 0.9886\n",
      "Epoch 00029: loss improved from 0.05671 to 0.05381, saving model to Farhan64_32.h5\n",
      "88/88 [==============================] - 65s 741ms/step - loss: 0.0538 - accuracy: 0.9886 - val_loss: 1.7623 - val_accuracy: 0.6882\n",
      "Epoch 30/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0846 - accuracy: 0.9829\n",
      "Epoch 00030: loss did not improve from 0.05381\n",
      "88/88 [==============================] - 64s 730ms/step - loss: 0.0846 - accuracy: 0.9829 - val_loss: 1.8858 - val_accuracy: 0.6989\n",
      "Epoch 31/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0943 - accuracy: 0.9600\n",
      "Epoch 00031: loss did not improve from 0.05381\n",
      "88/88 [==============================] - 64s 730ms/step - loss: 0.0943 - accuracy: 0.9600 - val_loss: 1.2920 - val_accuracy: 0.7419\n",
      "Epoch 32/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0738 - accuracy: 0.9657\n",
      "Epoch 00032: loss did not improve from 0.05381\n",
      "88/88 [==============================] - 64s 730ms/step - loss: 0.0738 - accuracy: 0.9657 - val_loss: 1.1836 - val_accuracy: 0.7419\n",
      "Epoch 33/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0542 - accuracy: 0.9886\n",
      "Epoch 00033: loss did not improve from 0.05381\n",
      "88/88 [==============================] - 64s 731ms/step - loss: 0.0542 - accuracy: 0.9886 - val_loss: 1.6730 - val_accuracy: 0.6559\n",
      "Epoch 34/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 1.0000\n",
      "Epoch 00034: loss improved from 0.05381 to 0.02328, saving model to Farhan64_32.h5\n",
      "88/88 [==============================] - 65s 744ms/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 1.7311 - val_accuracy: 0.6882\n",
      "Epoch 35/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9943\n",
      "Epoch 00035: loss improved from 0.02328 to 0.01595, saving model to Farhan64_32.h5\n",
      "88/88 [==============================] - 65s 743ms/step - loss: 0.0160 - accuracy: 0.9943 - val_loss: 1.4747 - val_accuracy: 0.7204\n",
      "Epoch 36/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 0.9829\n",
      "Epoch 00036: loss did not improve from 0.01595\n",
      "88/88 [==============================] - 64s 731ms/step - loss: 0.0430 - accuracy: 0.9829 - val_loss: 2.3091 - val_accuracy: 0.6237\n",
      "Epoch 37/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0723 - accuracy: 0.9771\n",
      "Epoch 00037: loss did not improve from 0.01595\n",
      "88/88 [==============================] - 64s 730ms/step - loss: 0.0723 - accuracy: 0.9771 - val_loss: 1.4337 - val_accuracy: 0.6882\n",
      "Epoch 38/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 0.9943\n",
      "Epoch 00038: loss did not improve from 0.01595\n",
      "88/88 [==============================] - 64s 729ms/step - loss: 0.0205 - accuracy: 0.9943 - val_loss: 1.2678 - val_accuracy: 0.7419\n",
      "Epoch 39/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0422 - accuracy: 0.9829\n",
      "Epoch 00039: loss did not improve from 0.01595\n",
      "88/88 [==============================] - 64s 730ms/step - loss: 0.0422 - accuracy: 0.9829 - val_loss: 1.1467 - val_accuracy: 0.7097\n",
      "Epoch 40/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9829\n",
      "Epoch 00040: loss did not improve from 0.01595\n",
      "88/88 [==============================] - 64s 730ms/step - loss: 0.0561 - accuracy: 0.9829 - val_loss: 1.7379 - val_accuracy: 0.6989\n",
      "Epoch 41/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0736 - accuracy: 0.9714\n",
      "Epoch 00041: loss did not improve from 0.01595\n",
      "88/88 [==============================] - 64s 731ms/step - loss: 0.0736 - accuracy: 0.9714 - val_loss: 0.9746 - val_accuracy: 0.7634\n",
      "Epoch 42/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 00042: loss improved from 0.01595 to 0.01055, saving model to Farhan64_32.h5\n",
      "88/88 [==============================] - 65s 744ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 1.0066 - val_accuracy: 0.7634\n",
      "Epoch 43/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 0.9886\n",
      "Epoch 00043: loss did not improve from 0.01055\n",
      "88/88 [==============================] - 64s 730ms/step - loss: 0.0304 - accuracy: 0.9886 - val_loss: 0.9707 - val_accuracy: 0.7312\n",
      "Epoch 44/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.9886\n",
      "Epoch 00044: loss did not improve from 0.01055\n",
      "88/88 [==============================] - 64s 732ms/step - loss: 0.0276 - accuracy: 0.9886 - val_loss: 1.4035 - val_accuracy: 0.7097\n",
      "Epoch 45/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0393 - accuracy: 0.9886\n",
      "Epoch 00045: loss did not improve from 0.01055\n",
      "88/88 [==============================] - 64s 731ms/step - loss: 0.0393 - accuracy: 0.9886 - val_loss: 1.1577 - val_accuracy: 0.7097\n",
      "Epoch 46/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 1.0000\n",
      "Epoch 00046: loss improved from 0.01055 to 0.01005, saving model to Farhan64_32.h5\n",
      "88/88 [==============================] - 65s 742ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.1014 - val_accuracy: 0.7419\n",
      "Epoch 47/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9943\n",
      "Epoch 00047: loss did not improve from 0.01005\n",
      "88/88 [==============================] - 64s 731ms/step - loss: 0.0321 - accuracy: 0.9943 - val_loss: 1.1452 - val_accuracy: 0.7527\n",
      "Epoch 48/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 00048: loss did not improve from 0.01005\n",
      "88/88 [==============================] - 64s 732ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.1883 - val_accuracy: 0.7419\n",
      "Epoch 49/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.1255 - accuracy: 0.9657\n",
      "Epoch 00049: loss did not improve from 0.01005\n",
      "88/88 [==============================] - 64s 732ms/step - loss: 0.1255 - accuracy: 0.9657 - val_loss: 2.0088 - val_accuracy: 0.6344\n",
      "Epoch 50/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.9829\n",
      "Epoch 00050: loss did not improve from 0.01005\n",
      "88/88 [==============================] - 64s 731ms/step - loss: 0.0440 - accuracy: 0.9829 - val_loss: 1.4617 - val_accuracy: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.9943\n",
      "Epoch 00051: loss did not improve from 0.01005\n",
      "88/88 [==============================] - 64s 731ms/step - loss: 0.0251 - accuracy: 0.9943 - val_loss: 1.4274 - val_accuracy: 0.7204\n",
      "Epoch 52/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 00052: loss improved from 0.01005 to 0.00384, saving model to Farhan64_32.h5\n",
      "88/88 [==============================] - 66s 746ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.4494 - val_accuracy: 0.7312\n",
      "Epoch 53/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 0.9943\n",
      "Epoch 00053: loss did not improve from 0.00384\n",
      "88/88 [==============================] - 64s 732ms/step - loss: 0.0132 - accuracy: 0.9943 - val_loss: 1.5666 - val_accuracy: 0.7204\n",
      "Epoch 54/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 1.0000\n",
      "Epoch 00054: loss did not improve from 0.00384\n",
      "88/88 [==============================] - 65s 734ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.5885 - val_accuracy: 0.7312\n",
      "Epoch 55/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.1420 - accuracy: 0.9657\n",
      "Epoch 00055: loss did not improve from 0.00384\n",
      "88/88 [==============================] - 64s 730ms/step - loss: 0.1420 - accuracy: 0.9657 - val_loss: 1.5236 - val_accuracy: 0.6989\n",
      "Epoch 56/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.2623 - accuracy: 0.9429\n",
      "Epoch 00056: loss did not improve from 0.00384\n",
      "88/88 [==============================] - 64s 731ms/step - loss: 0.2623 - accuracy: 0.9429 - val_loss: 1.6821 - val_accuracy: 0.6452\n",
      "Epoch 57/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9829\n",
      "Epoch 00057: loss did not improve from 0.00384\n",
      "88/88 [==============================] - 64s 731ms/step - loss: 0.0442 - accuracy: 0.9829 - val_loss: 1.4821 - val_accuracy: 0.6667\n",
      "Epoch 58/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0434 - accuracy: 0.9829\n",
      "Epoch 00058: loss did not improve from 0.00384\n",
      "88/88 [==============================] - 64s 731ms/step - loss: 0.0434 - accuracy: 0.9829 - val_loss: 1.5023 - val_accuracy: 0.7312\n",
      "Epoch 59/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9943\n",
      "Epoch 00059: loss did not improve from 0.00384\n",
      "88/88 [==============================] - 64s 728ms/step - loss: 0.0351 - accuracy: 0.9943 - val_loss: 1.6386 - val_accuracy: 0.6882\n",
      "Epoch 60/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0307 - accuracy: 0.9829\n",
      "Epoch 00060: loss did not improve from 0.00384\n",
      "88/88 [==============================] - 64s 730ms/step - loss: 0.0307 - accuracy: 0.9829 - val_loss: 1.4891 - val_accuracy: 0.7312\n",
      "Epoch 61/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0393 - accuracy: 0.9886\n",
      "Epoch 00061: loss did not improve from 0.00384\n",
      "88/88 [==============================] - 64s 733ms/step - loss: 0.0393 - accuracy: 0.9886 - val_loss: 1.2854 - val_accuracy: 0.7312\n",
      "Epoch 62/1000\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9943\n",
      "Epoch 00062: loss did not improve from 0.00384\n",
      "88/88 [==============================] - 64s 728ms/step - loss: 0.0173 - accuracy: 0.9943 - val_loss: 1.4020 - val_accuracy: 0.7312\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                                 monitor='loss',\n",
    "                                 verbose=1,\n",
    "                                 save_best_only=True)\n",
    "stop = EarlyStopping(monitor='loss', patience = 10,\n",
    "                      verbose=0, mode='auto', baseline=None, \n",
    "                      restore_best_weights=False)\n",
    "callbacks = [checkpoint,stop]\n",
    "#history = model.fit([Xf_train, X_train], Y_train, epochs=1000, batch_size = 3 , shuffle=True, validation_split=0.2, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use LSTM model to predict\n",
    "\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# y_pred_ohe = model.predict(X_test)\n",
    "# y_pred_labels = np.argmax(y_pred_ohe, axis=1)\n",
    "# y_true_labels = y_test\n",
    "# confusion_matrix = metrics.confusion_matrix(y_true=y_true_labels, y_pred=y_pred_labels)\n",
    "# print(y_true_labels)\n",
    "\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "# sns.heatmap(confusion_matrix, xticklabels=classes, yticklabels=classes, annot=True, fmt=\"d\");\n",
    "# plt.title(\"Confusion matrix\")\n",
    "# plt.ylabel('True label')\n",
    "# plt.xlabel('Predicted label')\n",
    "\n",
    "# plt.show();\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='best')\n",
    "plt.savefig('model-acc.png')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='best')\n",
    "plt.savefig('model-loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"model_har.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
