{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential, Model \n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from keras_video import VideoFrameGenerator\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ApplyEyeMakeup',\n",
       " 'ApplyLipstick',\n",
       " 'Archery',\n",
       " 'BabyCrawling',\n",
       " 'BalanceBeam',\n",
       " 'BandMarching',\n",
       " 'BaseballPitch',\n",
       " 'Basketball',\n",
       " 'BasketballDunk',\n",
       " 'BenchPress',\n",
       " 'Biking',\n",
       " 'Billiards',\n",
       " 'BlowDryHair',\n",
       " 'BlowingCandles',\n",
       " 'BodyWeightSquats',\n",
       " 'Bowling',\n",
       " 'BoxingPunchingBag',\n",
       " 'BoxingSpeedBag',\n",
       " 'BreastStroke',\n",
       " 'BrushingTeeth',\n",
       " 'CleanAndJerk',\n",
       " 'CliffDiving',\n",
       " 'CricketBowling',\n",
       " 'CricketShot',\n",
       " 'CuttingInKitchen',\n",
       " 'Diving',\n",
       " 'Drumming',\n",
       " 'Fencing',\n",
       " 'FieldHockeyPenalty',\n",
       " 'FloorGymnastics',\n",
       " 'FrisbeeCatch',\n",
       " 'FrontCrawl',\n",
       " 'GolfSwing',\n",
       " 'Haircut',\n",
       " 'HammerThrow',\n",
       " 'Hammering',\n",
       " 'HandstandPushups',\n",
       " 'HandstandWalking',\n",
       " 'HeadMassage',\n",
       " 'HighJump',\n",
       " 'HorseRace',\n",
       " 'HorseRiding',\n",
       " 'HulaHoop',\n",
       " 'IceDancing',\n",
       " 'JavelinThrow',\n",
       " 'JugglingBalls',\n",
       " 'JumpRope',\n",
       " 'JumpingJack',\n",
       " 'Kayaking',\n",
       " 'Knitting',\n",
       " 'LongJump',\n",
       " 'Lunges',\n",
       " 'MilitaryParade',\n",
       " 'Mixing',\n",
       " 'MoppingFloor',\n",
       " 'Nunchucks',\n",
       " 'ParallelBars',\n",
       " 'PizzaTossing',\n",
       " 'PlayingCello',\n",
       " 'PlayingDaf',\n",
       " 'PlayingDhol',\n",
       " 'PlayingFlute',\n",
       " 'PlayingGuitar',\n",
       " 'PlayingPiano',\n",
       " 'PlayingSitar',\n",
       " 'PlayingTabla',\n",
       " 'PlayingViolin',\n",
       " 'PoleVault',\n",
       " 'PommelHorse',\n",
       " 'PullUps',\n",
       " 'Punch',\n",
       " 'PushUps',\n",
       " 'Rafting',\n",
       " 'RockClimbingIndoor',\n",
       " 'RopeClimbing',\n",
       " 'Rowing',\n",
       " 'SalsaSpin',\n",
       " 'ShavingBeard',\n",
       " 'Shotput',\n",
       " 'SkateBoarding',\n",
       " 'Skiing',\n",
       " 'Skijet',\n",
       " 'SkyDiving',\n",
       " 'SoccerJuggling',\n",
       " 'SoccerPenalty',\n",
       " 'StillRings',\n",
       " 'SumoWrestling',\n",
       " 'Surfing',\n",
       " 'Swing',\n",
       " 'TableTennisShot',\n",
       " 'TaiChi',\n",
       " 'TennisSwing',\n",
       " 'ThrowDiscus',\n",
       " 'TrampolineJumping',\n",
       " 'Typing',\n",
       " 'UnevenBars',\n",
       " 'VolleyballSpiking',\n",
       " 'WalkingWithDog',\n",
       " 'WallPushups',\n",
       " 'WritingOnBoard',\n",
       " 'YoYo']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# classes = [\"Backstroke\", \"Breaststroke\", \"Freestyle\"]\n",
    "with open('ucf101_data/classInd.txt') as f:\n",
    "    classes = f.readlines()\n",
    "# you may also want to remove whitespace characters like `\\n` at the end of each line\n",
    "classes = [x.strip() for x in classes] \n",
    "classes.sort()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_height , img_width = 64, 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: 101 classes for 9537 files for train\n"
     ]
    }
   ],
   "source": [
    "# some global params\n",
    "SIZE = (img_height, img_width)\n",
    "CHANNELS = 3\n",
    "NBFRAME =20\n",
    "BS = 9537\n",
    "# pattern to get videos and classes\n",
    "glob_pattern='ucf101_data/train/{classname}/*.avi'\n",
    "# for data augmentation\n",
    "data_aug = ImageDataGenerator(\n",
    "#     zoom_range=1.5,\n",
    "#     horizontal_flip=True,\n",
    "#     rotation_range=8,\n",
    "#     width_shift_range=.2,\n",
    "#     height_shift_range=.2\n",
    ")\n",
    "# Create video frame generator\n",
    "\n",
    "train = VideoFrameGenerator(\n",
    "    classes=classes, \n",
    "    glob_pattern=glob_pattern,\n",
    "    nb_frames=NBFRAME,\n",
    "#     split_val=0.25, \n",
    "#     shuffle=True,\n",
    "    batch_size=BS,\n",
    "    target_shape=SIZE,\n",
    "    nb_channel=CHANNELS,\n",
    "#     transformation=data_aug,\n",
    "    use_frame_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: 101 classes for 3783 files for train\n"
     ]
    }
   ],
   "source": [
    "\n",
    "glob_test='ucf101_data/test/{classname}/*.avi'\n",
    "valid = VideoFrameGenerator(\n",
    "    classes=classes, \n",
    "    glob_pattern=glob_test,\n",
    "    nb_frames=NBFRAME,\n",
    "#     split=.2, \n",
    "    shuffle=True,\n",
    "    batch_size=3783,\n",
    "    target_shape=SIZE,\n",
    "    nb_channel=CHANNELS,\n",
    "#     transformation=data_aug,\n",
    "    use_frame_cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data: 101 classes for 0 files for validation\n"
     ]
    }
   ],
   "source": [
    "valid = train.get_validation_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_video.generator.VideoFrameGenerator at 0x24fc8e834a8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "x_train, y_train = next(train)\n",
    "# x_test, y_test = next(valid)\n",
    "\n",
    "elapsed_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.051668866475423 minutes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(str(elapsed_time/60)+' minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9537, 20, 64, 64, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = \"ucf101_data/train\"\n",
    "# img_height , img_width = 200, 180\n",
    "# seq_len = 60\n",
    " \n",
    "# #  Creating frames from videos\n",
    "# def frames_extraction(video_path):\n",
    "#     frames_list = []\n",
    "     \n",
    "#     vidObj = cv2.VideoCapture(video_path)\n",
    "#     # Used as counter variable \n",
    "#     count = 1\n",
    " \n",
    "#     while count <= seq_len: \n",
    "         \n",
    "#         success, image = vidObj.read() \n",
    "#         if success:\n",
    "#             image = cv2.resize(image, (img_height, img_width))\n",
    "#             frames_list.append(image)\n",
    "#             count += 1\n",
    "#         else:\n",
    "#             print(\"Defected frame\")\n",
    "#             break\n",
    " \n",
    "            \n",
    "#     return frames_list\n",
    " \n",
    "# def create_data(input_dir):\n",
    "#     X = []\n",
    "#     Y = []\n",
    "     \n",
    "#     classes_list = os.listdir(input_dir)\n",
    "     \n",
    "#     for c in classes_list:\n",
    "#         print(c)\n",
    "#         files_list = os.listdir(os.path.join(input_dir, c))\n",
    "#         for f in files_list:\n",
    "#             frames = frames_extraction(os.path.join(os.path.join(input_dir, c), f))\n",
    "#             if len(frames) == seq_len:\n",
    "#                 X.append(frames)\n",
    "             \n",
    "#                 y = [0]*len(classes)\n",
    "#                 y[classes.index(c)] = 1\n",
    "#                 Y.append(y)\n",
    "     \n",
    "#     X = np.asarray(X)\n",
    "#     Y = np.asarray(Y)\n",
    "#     return X, Y\n",
    " \n",
    "# X, Y = create_data(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d (ConvLSTM2D)    (None, 20, 64, 64, 64)    429056    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 20, 64, 64, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_1 (ConvLSTM2D)  (None, 60, 60, 32)        307328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60, 60, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 115200)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               58982912  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 101)               25957     \n",
      "=================================================================\n",
      "Total params: 59,876,581\n",
      "Trainable params: 59,876,581\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/400\n",
      "1817/3576 [==============>...............] - ETA: 9:07 - loss: 4.3598 - accuracy: 0.0759"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.25, shuffle=True, random_state=0)\n",
    "filepath = 'best_model_convlstm_fix.h5'\n",
    "\n",
    "model = Sequential()\n",
    "model.add(ConvLSTM2D(filters = 64, kernel_size = (5, 5), padding='same',return_sequences = True, data_format = \"channels_last\", \n",
    "                     input_shape = (NBFRAME, img_width, img_height, 3),kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\n",
    "# model.add(ConvLSTM2D(filters = 64, kernel_size = (3, 3), padding='same',return_sequences = True, data_format = \"channels_last\", \n",
    "#                      input_shape = (NBFRAME,64,64, 3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(ConvLSTM2D(filters = 32, kernel_size = (5, 5), return_sequences = False, data_format = \"channels_last\",kernel_regularizer=tf.keras.regularizers.l2(0.0001)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(classes), activation = \"softmax\"))\n",
    " \n",
    "model.summary()\n",
    "'''\n",
    "model = Sequential()\n",
    "# input_shape: (time_steps, map_height, map_width, channels)\n",
    "model.add(ConvLSTM2D(filters = 32, kernel_size = (3, 3),  input_shape = (NBFRAME, img_width, img_height, 3), return_sequences = True))\n",
    "model.add(ConvLSTM2D(filters = 32, kernel_size = (3, 3), return_sequences = True))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(ConvLSTM2D(filters = 32, kernel_size = (3, 3), return_sequences = True))\n",
    "model.add(ConvLSTM2D(filters = 32, kernel_size = (3, 3), return_sequences = True))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(MaxPooling3D((1, 2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(ConvLSTM2D(filters = 32, kernel_size = (3, 3), return_sequences = True))\n",
    "model.add(ConvLSTM2D(filters = 32, kernel_size = (3, 3), return_sequences = True))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(LeakyReLU(alpha=0.2))\n",
    "#model.add(AveragePooling3D((1, 2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(ConvLSTM2D(filters = 32, kernel_size = (3, 3), return_sequences = True))\n",
    "model.add(ConvLSTM2D(filters = 32, kernel_size = (3, 3), return_sequences = False))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(AveragePooling2D((2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()\n",
    "'''\n",
    "opt = optimizers.Adam(lr=0.00005)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n",
    " \n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "stop = EarlyStopping(monitor='val_loss', patience =5,\n",
    "                      verbose=0, mode='auto', baseline=None, \n",
    "                      restore_best_weights=False)\n",
    "callbacks = [checkpoint,stop]\n",
    " \n",
    "history = model.fit(x = X_train, y = y_train, epochs=400, batch_size = 2 , shuffle=True, validation_data=(X_test,y_test), callbacks=callbacks)\n",
    "# history = model.fit_generator(\n",
    "#     train,\n",
    "#     validation_data=valid,\n",
    "#     verbose=1,\n",
    "#     epochs=400, \n",
    "#     callbacks=callbacks\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = model.predict(X_test)\n",
    "# y_pred = np.argmax(y_pred, axis = 1)\n",
    "# # y_test = np.argmax(y_test, axis = 1)\n",
    " \n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use LSTM model to predict\n",
    "\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# y_pred_ohe = model.predict(X_test)\n",
    "# y_pred_labels = np.argmax(y_pred_ohe, axis=1)\n",
    "# y_true_labels = y_test\n",
    "# confusion_matrix = metrics.confusion_matrix(y_true=y_true_labels, y_pred=y_pred_labels)\n",
    "# print(y_true_labels)\n",
    "\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "# sns.heatmap(confusion_matrix, xticklabels=classes, yticklabels=classes, annot=True, fmt=\"d\");\n",
    "# plt.title(\"Confusion matrix\")\n",
    "# plt.ylabel('True label')\n",
    "# plt.xlabel('Predicted label')\n",
    "# plt.show();\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_har.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
