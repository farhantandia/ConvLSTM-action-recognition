{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.models import Sequential, Model \n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_video import VideoFrameGenerator\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras_metrics as km\n",
    "import glob\n",
    " \n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./videodata_tmp/\"\n",
    "filename = \"ConvLSTM_model_UCF101.h5\"\n",
    "h, w = 224, 224\n",
    "time_steps = 64\n",
    "\n",
    "#classes = [\"Backstroke\", \"Breaststroke\", \"Freestyle\"]\n",
    "classes = [i.split(os.path.sep)[1] for i in glob.glob('./videodata_tmp/*')]\n",
    "classes.sort()\n",
    "#print(classes)\n",
    "\n",
    "#glob_pattern='./videodata/{classname}/*.avi'\n",
    "\n",
    "#data_aug = ImageDataGenerator(\n",
    "#    zoom_range = [0.6, 1.2],\n",
    "#    horizontal_flip = True,\n",
    "#    rotation_range = 180,\n",
    "#    width_shift_range = 0,\n",
    "#    height_shift_range = 0)\n",
    "\n",
    "#train = VideoFrameGenerator(\n",
    "#    classes=classes, \n",
    "#    glob_pattern=glob_pattern,\n",
    "#    nb_frames=time_steps,\n",
    "#    split = 0.3, \n",
    "#    shuffle = True,\n",
    "#    batch_size = 1,\n",
    "#    target_shape = (w, h),\n",
    "#    nb_channel = 3,\n",
    "#    transformation=data_aug,\n",
    "#    use_frame_cache=True)\n",
    "#valid = train.get_validation_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ApplyEyeMakeup', 'ApplyLipstick', 'Archery', 'BabyCrawling', 'BalanceBeam', 'BandMarching', 'BaseballPitch', 'Basketball', 'BasketballDunk', 'BenchPress', 'Biking', 'Billiards', 'BlowDryHair', 'BlowingCandles', 'BodyWeightSquats', 'Bowling', 'BoxingPunchingBag', 'BoxingSpeedBag', 'BreastStroke', 'BrushingTeeth', 'CleanAndJerk', 'CliffDiving', 'CricketBowling', 'CricketShot', 'CuttingInKitchen', 'Diving', 'Drumming', 'Fencing', 'FieldHockeyPenalty', 'FloorGymnastics', 'FrisbeeCatch', 'FrontCrawl', 'GolfSwing', 'Haircut', 'Hammering', 'HammerThrow', 'HandstandPushups', 'HandstandWalking', 'HeadMassage', 'HighJump', 'HorseRace', 'HorseRiding', 'HulaHoop', 'IceDancing', 'JavelinThrow', 'JugglingBalls', 'JumpingJack', 'JumpRope', 'Kayaking', 'Knitting', 'LongJump', 'Lunges', 'MilitaryParade', 'Mixing', 'MoppingFloor', 'Nunchucks', 'ParallelBars', 'PizzaTossing', 'PlayingCello', 'PlayingDaf', 'PlayingDhol', 'PlayingFlute', 'PlayingGuitar', 'PlayingPiano', 'PlayingSitar', 'PlayingTabla', 'PlayingViolin', 'PoleVault', 'PommelHorse', 'PullUps', 'Punch', 'PushUps', 'Rafting', 'RockClimbingIndoor', 'RopeClimbing', 'Rowing', 'SalsaSpin', 'ShavingBeard', 'Shotput', 'SkateBoarding', 'Skiing', 'Skijet', 'SkyDiving', 'SoccerJuggling', 'SoccerPenalty', 'StillRings', 'SumoWrestling', 'Surfing', 'Swing', 'TableTennisShot', 'TaiChi', 'TennisSwing', 'ThrowDiscus', 'TrampolineJumping', 'Typing', 'UnevenBars', 'VolleyballSpiking', 'WalkingWithDog', 'WallPushups', 'WritingOnBoard', 'YoYo']\n",
      "ApplyEyeMakeup\n",
      "ApplyLipstick\n",
      "Archery\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "BabyCrawling\n",
      "BalanceBeam\n",
      "Defected frame\n",
      "Defected frame\n",
      "BandMarching\n",
      "Defected frame\n",
      "Defected frame\n",
      "BaseballPitch\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Basketball\n",
      "Defected frame\n",
      "Defected frame\n",
      "BasketballDunk\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "BenchPress\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Biking\n",
      "Billiards\n",
      "BlowDryHair\n",
      "BlowingCandles\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "BodyWeightSquats\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "Bowling\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n",
      "BoxingPunchingBag\n",
      "BoxingSpeedBag\n",
      "BreastStroke\n",
      "BrushingTeeth\n",
      "CleanAndJerk\n",
      "CliffDiving\n",
      "Defected frame\n",
      "Defected frame\n",
      "Defected frame\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#  Creating frames from videos\n",
    "def frames_extraction(video_path):\n",
    "    frames = []\n",
    "     \n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    # Used as counter variable \n",
    "    count = 1\n",
    "    while count <= time_steps:\n",
    "        ret, img = video.read() \n",
    "        if ret:\n",
    "            img = cv2.resize(img, (w, h))\n",
    "            frames.append(img)\n",
    "            count += 1\n",
    "        else:\n",
    "            print(\"Defected frame\")\n",
    "            break\n",
    "    return frames\n",
    "    #rotate_frames = []\n",
    "    #for img in frames:\n",
    "        #rimg = cv2.rotate(img, cv2.ROTATE_180)\n",
    "        #rotate_frames.append(rimg)\n",
    "\n",
    "    #return frames, rotate_frames\n",
    "\n",
    "def create_data(input_dir):\n",
    "    X = []\n",
    "    Y = []\n",
    "     \n",
    "    classes_list = os.listdir(input_dir)\n",
    "    print(classes_list)\n",
    "    for c in classes_list:\n",
    "        print(c)\n",
    "        files_list = os.listdir(os.path.join(input_dir, c))\n",
    "        for f in files_list:\n",
    "            \n",
    "            frames = frames_extraction(os.path.join(os.path.join(input_dir, c), f))\n",
    "            \n",
    "            if len(frames) == time_steps:\n",
    "                X.append(frames)\n",
    "                y = [0]*len(classes)\n",
    "                y[classes.index(c)] = 1\n",
    "                Y.append(y)\n",
    "             \n",
    "                \n",
    "            #if len(frames) == time_steps and len(rotate_frames) == time_steps:\n",
    "            #    X.append(frames)\n",
    "            #    y = [0]*len(classes)\n",
    "            #    y[classes.index(c)] = 1\n",
    "            #    Y.append(y)\n",
    "                \n",
    "            #    X.append(rotate_frames)\n",
    "            #    y = [0]*len(classes)\n",
    "            #    y[classes.index(c)] = 1\n",
    "            #    Y.append(y)\n",
    "    X = np.asarray(X)\n",
    "    Y = np.asarray(Y)\n",
    "    return X, Y\n",
    "\n",
    "X, Y = create_data(data_dir)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, shuffle=True, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_lst_m2d_4 (ConvLSTM2D)  (None, 10, 68, 43, 16)    11008     \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_5 (ConvLSTM2D)  (None, 10, 66, 41, 16)    18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10, 66, 41, 16)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 10, 66, 41, 16)    64        \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 66, 41, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_6 (ConvLSTM2D)  (None, 10, 64, 39, 16)    18496     \n",
      "_________________________________________________________________\n",
      "conv_lst_m2d_7 (ConvLSTM2D)  (None, 10, 62, 37, 16)    18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10, 62, 37, 16)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 10, 62, 37, 16)    64        \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 10, 62, 37, 16)    0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 367040)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               46981248  \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 47,048,259\n",
      "Trainable params: 47,048,195\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "81/81 [==============================] - ETA: 0s - loss: 1.4321 - accuracy: 0.5309\n",
      "Epoch 00001: val_loss improved from inf to 1.05458, saving model to ConvLSTM_model.h5\n",
      "81/81 [==============================] - 10s 125ms/step - loss: 1.4321 - accuracy: 0.5309 - val_loss: 1.0546 - val_accuracy: 0.5610\n",
      "Epoch 2/1000\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.4336 - accuracy: 0.8457\n",
      "Epoch 00002: val_loss improved from 1.05458 to 1.01070, saving model to ConvLSTM_model.h5\n",
      "81/81 [==============================] - 9s 115ms/step - loss: 0.4336 - accuracy: 0.8457 - val_loss: 1.0107 - val_accuracy: 0.5122\n",
      "Epoch 3/1000\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.1711 - accuracy: 0.9506\n",
      "Epoch 00003: val_loss improved from 1.01070 to 0.78920, saving model to ConvLSTM_model.h5\n",
      "81/81 [==============================] - 9s 116ms/step - loss: 0.1711 - accuracy: 0.9506 - val_loss: 0.7892 - val_accuracy: 0.8293\n",
      "Epoch 4/1000\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.1396 - accuracy: 0.9444\n",
      "Epoch 00004: val_loss improved from 0.78920 to 0.75599, saving model to ConvLSTM_model.h5\n",
      "81/81 [==============================] - 9s 117ms/step - loss: 0.1396 - accuracy: 0.9444 - val_loss: 0.7560 - val_accuracy: 0.6098\n",
      "Epoch 5/1000\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0364 - accuracy: 0.9938\n",
      "Epoch 00005: val_loss improved from 0.75599 to 0.40261, saving model to ConvLSTM_model.h5\n",
      "81/81 [==============================] - 9s 117ms/step - loss: 0.0364 - accuracy: 0.9938 - val_loss: 0.4026 - val_accuracy: 0.8780\n",
      "Epoch 6/1000\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0295 - accuracy: 0.9938\n",
      "Epoch 00006: val_loss did not improve from 0.40261\n",
      "81/81 [==============================] - 6s 70ms/step - loss: 0.0295 - accuracy: 0.9938 - val_loss: 0.4249 - val_accuracy: 0.8293\n",
      "Epoch 7/1000\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 1.0000\n",
      "Epoch 00007: val_loss did not improve from 0.40261\n",
      "81/81 [==============================] - 6s 70ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.4183 - val_accuracy: 0.8537\n",
      "Epoch 8/1000\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 00008: val_loss improved from 0.40261 to 0.30637, saving model to ConvLSTM_model.h5\n",
      "81/81 [==============================] - 10s 118ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.3064 - val_accuracy: 0.8537\n",
      "Epoch 9/1000\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 00009: val_loss improved from 0.30637 to 0.24036, saving model to ConvLSTM_model.h5\n",
      "81/81 [==============================] - 9s 117ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.2404 - val_accuracy: 0.9024\n",
      "Epoch 10/1000\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 00010: val_loss improved from 0.24036 to 0.23200, saving model to ConvLSTM_model.h5\n",
      "81/81 [==============================] - 10s 119ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.2320 - val_accuracy: 0.9268\n",
      "Epoch 11/1000\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0833 - accuracy: 0.9691\n",
      "Epoch 00011: val_loss did not improve from 0.23200\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.0833 - accuracy: 0.9691 - val_loss: 0.8480 - val_accuracy: 0.7073\n",
      "Epoch 12/1000\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9938\n",
      "Epoch 00012: val_loss did not improve from 0.23200\n",
      "81/81 [==============================] - 6s 72ms/step - loss: 0.0186 - accuracy: 0.9938 - val_loss: 0.3238 - val_accuracy: 0.8293\n",
      "Epoch 13/1000\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 1.0000\n",
      "Epoch 00013: val_loss improved from 0.23200 to 0.11398, saving model to ConvLSTM_model.h5\n",
      "81/81 [==============================] - 10s 118ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.1140 - val_accuracy: 0.9268\n",
      "Epoch 14/1000\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9938\n",
      "Epoch 00014: val_loss did not improve from 0.11398\n",
      "81/81 [==============================] - 6s 75ms/step - loss: 0.0159 - accuracy: 0.9938 - val_loss: 0.1612 - val_accuracy: 0.9268\n",
      "Epoch 15/1000\n",
      "81/81 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 00015: val_loss did not improve from 0.11398\n",
      "81/81 [==============================] - 6s 73ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.1492 - val_accuracy: 0.9512\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# input_shape: (time_steps, map_height, map_width, channels)\n",
    "model.add(ConvLSTM2D(filters = 16, kernel_size = (3, 3), input_shape = (time_steps, h, w, 3), return_sequences = True))\n",
    "model.add(ConvLSTM2D(filters = 16, kernel_size = (3, 3), return_sequences = True))\n",
    "#model.add(LeakyReLU(alpha=0.3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(ConvLSTM2D(filters = 16, kernel_size = (3, 3), return_sequences = True))\n",
    "model.add(ConvLSTM2D(filters = 16, kernel_size = (3, 3), return_sequences = True))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "opt = Adam(lr=1e-5)\n",
    "#opt = SGD(lr=0.0001)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=filename,\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "stop = EarlyStopping(monitor='loss', patience = 5,\n",
    "                      verbose=0, mode='auto', baseline=None, \n",
    "                      restore_best_weights=False)\n",
    "callbacks = [checkpoint, stop]\n",
    "\n",
    "history = model.fit(x = X_train, y = y_train, epochs = 1000, batch_size = 2, shuffle=True, validation_split=0.2, callbacks=callbacks)\n",
    "#history = model.fit(train, validation_data=valid, verbose=1, epochs=50, shuffle=True, callbacks=callbacks)\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train = model.predict(X_train)\n",
    "#y_val = model.predict(X_test)\n",
    "\n",
    "#y_train = np.argmax(y_train, axis = 1)\n",
    "#y_val = np.argmax(y_val, axis = 1)\n",
    "\n",
    "#print(\"Train: \"+str(y_train))\n",
    "#print(\"Validation: \"+str(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
